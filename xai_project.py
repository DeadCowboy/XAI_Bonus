# -*- coding: utf-8 -*-
"""xai_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BQTAeVaNqR2whhuCjP51TkUPmPMl1-bY

# Comparison of differently fine-tuned ResNets

## 0. Research Question
How does fine-tuning a model change the interpretability and concept assigment of specific deep neurons.

## 1. Choosing the channels
- take top-k channels over all data in the last layer
- top-k channels for specific classes of interest

## 2. How to compare the channels
- evaluate meaning and concept assigment
- note down specific channels that are important

## 3. Finding meaningful differences
- compare top-k channels, how has the importance of concepts changed
- compare the same channel before and after finetuning. Does the channel code for a new concept?


## TODO
1. Method to find semantacity of channel
  - top-k for channel over all data?
2. Find list of fine-tuned ResNets

general Resnet: https://huggingface.co/microsoft/resnet-50
Cats and Dogs: https://huggingface.co/tangocrazyguy/resnet-50-finetuned-cats_vs_dogs




All finetunings: https://huggingface.co/models?other=base_model:finetune:microsoft/resnet-50
"""

# Installs
# !pip install transformers
# !pip install -U datasets
# !pip install captum

# Imports
from transformers import ResNetForImageClassification
from datasets import load_dataset
from torchvision import transforms
from torch.utils.data import DataLoader
import torch
import numpy as np
from tqdm import tqdm

from typing import List


device = torch.device("cpu")


# ResNet50
def load_resnet50_default():
    model = ResNetForImageClassification.from_pretrained("microsoft/resnet-50")
    model = model.to(device)
    model.eval()
    return model


def load_dataset_imagenet1k():
    dataset = load_dataset("ILSVRC/imagenet-1k")
    return dataset


# ResNet50 - Cats and Dogs


def load_resnet50_cats_and_dogs():
    model = ResNetForImageClassification.from_pretrained("tangocrazyguy/resnet-50-finetuned-cats_vs_dogs")
    model = model.to(device)
    model.eval()
    return model


def load_dataset_cats_and_dogs():
    dataset = load_dataset("microsoft/cats_vs_dogs")
    return dataset


# Load Model and Dataset
model = load_resnet50_cats_and_dogs()
dataset = load_dataset_cats_and_dogs()


def start_pipeline(model, dataset):

    # Register hook
    activation = []

    def hook(model, input, output):
        activation.append(output.detach())  # .cpu()?

    model.resnet.encoder.stages[3].layers[2].register_forward_hook(hook)

    # Define transformation
    transform = transforms.Compose(
        [
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )

    # Run Dataset through model
    training = DataLoader(dataset["train"], batch_size=None)
    i = 0
    correct = 0
    for sample in tqdm(iter(training)):
        img = transform(sample["image"].convert("RGB"))  # Extract the image tensor from the dictionary
        img = img.unsqueeze(0)
        img = img.to(device)
        label = sample["labels"]
        with torch.no_grad():
            try:
                output = model(img)
                output = output.logits
                pred = torch.argmax(output).item()
                del img
                del output
                if pred == label:
                    correct += 1
                i += 1
                if i % 1000 == 0:
                    print(i, f"Acc: {correct / i}")
            except Exception as e:
                print(f"Size: {img.shape}")
                print(e)
        if i == 10:
            break
    print(f"Accuracy: {correct/i}")
    return activation


# Run pipeline


def getActivationValue(activationsList: List[torch.tensor]):
    act_max = torch.max(activationsList, dim=0, keepdim=True)
    act_min = torch.min(activationsList, dim=0, keepdim=True)
    return act_max / act_min


act = start_pipeline(model, dataset)
act_norm = getActivationValue(act)

print(act_norm)
